{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome!","text":""},{"location":"#docker-for-ai-in-science","title":"Docker for AI in Science","text":"<p>Welcome to the material for Docker in AI for Science!</p> <p>In this workshop, we will introduce Docker and how it can be used to accelerate your scientific research. We will cover the basics of Docker, how to create your own Docker images, and how to use Docker to run your code in a reproducible way.</p> <p>The workshop is divided into the following sections:</p>"},{"location":"#understanding-docker","title":"Understanding Docker","text":""},{"location":"#what-is-it","title":"What is it?","text":"<ul> <li> <p>Key concepts:</p> <ul> <li>Images</li> <li>Containers</li> <li>Registries</li> </ul> </li> <li> <p>Containers vs VMs</p> </li> </ul>"},{"location":"#why-it-matters","title":"Why it matters?","text":"<ul> <li> <p>Research benefits</p> <ul> <li>Reproducibility</li> <li>Portability</li> <li>Scalability</li> </ul> </li> <li> <p>Industry connection</p> <ul> <li>Need for data scientists</li> <li>Cloud deployment</li> <li>Skills for the future</li> </ul> </li> </ul>"},{"location":"#hands-on","title":"Hands on","text":""},{"location":"#getting-started","title":"Getting started","text":"<ul> <li>Working with basic images</li> <li>Working with scientific images</li> <li>Managing data volumes</li> </ul>"},{"location":"#building-your-own-images","title":"Building your own images","text":"<ul> <li>Dockerfiles</li> <li>Best practices</li> <li>Exercise: create your own image, upload it and then share it</li> </ul>"},{"location":"devcontainers/","title":"Devcontainers","text":"<p>In the reproducibility section, we talked about the different levels of reproducibilty. You are probably familiar with things like Python venvs, conda environments, and even virtual machines. These are all ways to isolate your code and dependencies from the rest of your system. But what if you could isolate your code and dependencies in a way that is even more portable and reproducible? That's where devcontainers come in.</p> <p>The Visual Studio Code Dev Containers extension lets you use a container as a dev environment. You can open any folder inside (or mounted into) a container inside VSCode. A <code>devcontainer.json</code> file in your project tells VS Code how to access (or create) a development container with a well-defined tool and runtime stack. This container can be used to run an application or to separate tools, libraries, or runtimes needed for working with a codebase.</p> <p>Workspace files are mounted from the local file system or copied or cloned into the container. Extensions are installed and run inside the container, where they have full access to the tools, platform, and file system. This means that you can seamlessly switch your entire development environment just by connecting to a different container.</p> <p> </p>"},{"location":"devcontainers/#basic","title":"Basic","text":"<p>Let's create a bare-bones devcontainer for our python project. Create a new folder:</p> <p><pre><code>mkdir .devcontainer\n</code></pre> and then create a new file: <pre><code>touch .devcontainer/devcontainer.json\n</code></pre> Now populate it with the following: <pre><code>{\n    \"name\": \"Research Environment\",\n    \"build\": {\n        \"dockerfile\": \"../Dockerfile\",\n        \"context\": \".\"\n    },\n    \"forwardPorts\": [8888]\n}\n</code></pre> This will create a new devcontainer called \"Research Environment\" that will use the Dockerfile in the parent directory. It will also forward port 8888 to the host machine.</p>"},{"location":"devcontainers/#better","title":"Better","text":"<p>This is very basic. We don't have much functionality here at all. And how do we even access the actual jupyter lab server? We don't even have the python extension installed in the container! We would also find that any changes to the the stuff inside the container would not be reflected in the host machine. So let's make our experience more enjoyable.</p> <pre><code>{\n    \"name\": \"Research Environment\",\n    \"build\": {\n        \"dockerfile\": \"../Dockerfile\",\n        \"context\": \"..\"\n    },\n\n    // Features to add to the dev container\n    \"features\": {\n        \"ghcr.io/devcontainers/features/git:1\": {}\n    },\n\n    // Configure tool-specific properties\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\n                \"ms-python.python\",\n                \"ms-python.vscode-pylance\",\n                \"ms-python.black-formatter\",\n                \"ms-toolsai.jupyter\",\n                \"github.copilot\"\n            ],\n            \"settings\": {\n                \"python.defaultInterpreterPath\": \"/usr/local/bin/python\",\n                \"python.linting.enabled\": true,\n                \"python.formatting.provider\": \"black\",\n                \"editor.formatOnSave\": true,\n                \"editor.rulers\": [88]\n            }\n        }\n    },\n\n    // Use 'forwardPorts' to make a list of ports inside the container available locally\n    \"forwardPorts\": [8888],\n\n    // Run commands after container is created\n    \"postCreateCommand\": \"pip install -r requirements.txt\",\n\n    // Set environment variables\n    \"remoteEnv\": {\n        \"PYTHONPATH\": \"${containerWorkspaceFolder}\"\n    },\n}\n</code></pre> <p>Now we have a lot more functionality!</p> <p>Let's look at exactly what is going on here:</p> <p>Top-level configuration <pre><code>\"name\": \"Research Environment\",\n</code></pre> This simply names your development container for easy identification.</p> <p>Build configuration <pre><code>\"build\": {\n    \"dockerfile\": \"../Dockerfile\",\n    \"context\": \"..\"\n}\n</code></pre> This tells VS Code how to build the container: - <code>dockerfile</code>: Points to a Dockerfile one directory up from the devcontainer.json - <code>context</code>: Sets the build context to the parent directory - what stuff to include in the build</p> <p>Features section <pre><code>\"features\": {\n    \"ghcr.io/devcontainers/features/git:1\": {}\n}\n</code></pre> This adds additional tools to your container. Here, it's installing Git from the GitHub Container Registry.</p> <p>VS Code Customizations <pre><code>\"customizations\": {\n    \"vscode\": {\n        \"extensions\": [...],\n        \"settings\": {...}\n    }\n}\n</code></pre> This configures VS Code-specific settings:</p> <ul> <li> <p>Extensions installed automatically:</p> <ul> <li>Python extension</li> <li>Pylance (Python language server)</li> <li>Black formatter</li> <li>Jupyter notebook support</li> <li>GitHub Copilot</li> </ul> </li> <li> <p>VS Code settings configured:</p> <ul> <li>Sets Python interpreter path</li> <li>Enables linting</li> <li>Uses Black for formatting</li> <li>Enables format-on-save</li> <li>Sets a line length ruler at 88 characters (Black's default)</li> </ul> </li> </ul> <p>We can add other dev tools here like mypy or itools or flake8.</p> <p>Port Forwarding <pre><code>\"forwardPorts\": [8888]\n</code></pre> Makes port 8888 (commonly used for Jupyter notebooks) available on your local machine.</p> <p>Post-Creation Commands <pre><code>\"postCreateCommand\": \"pip install -r requirements.txt\"\n</code></pre> Runs after the container is created - in this case, installing Python dependencies from requirements.txt.</p> <p>Environment Variables <pre><code>\"remoteEnv\": {\n    \"PYTHONPATH\": \"${containerWorkspaceFolder}\"\n}\n</code></pre> Sets environment variables in the container:</p> <ul> <li>Adds the workspace folder to Python's module search path, letting you import from any subdirectory</li> </ul> <p>This configuration creates a fully-featured Python development environment with:</p> <ul> <li>Code formatting and linting</li> <li>Jupyter notebook support</li> <li>Git integration</li> <li>Automatic dependency installation</li> <li>Proper Python path configuration</li> <li>AI assistance through Copilot</li> </ul> <p>We are also free to add other features such as poetry.</p>"},{"location":"docker/","title":"Understanding Docker","text":""},{"location":"docker/#what-is-docker","title":"What is Docker?","text":"<p>Imagine you're writing a paper that involves computational analysis. You've written your code, processed your data, and generated your figures. Six months later, a reviewer asks for revisions. You open your code and... nothing works. Maybe you've updated Python, or installed new packages that conflict with old ones, or switched computers entirely.</p> <p>This is where Docker comes in.</p> <p>Docker lets you create a complete, isolated environment that contains: - Your code - All required software and dependencies - Specific versions of languages and tools - Configuration settings</p> <p>Think of it like a scientific protocol - just as protocols ensure experimental reproducibility, Docker ensures computational reproducibility.</p>"},{"location":"docker/#key-concepts","title":"Key Concepts","text":""},{"location":"docker/#containers","title":"Containers","text":"<p>A container is like a lightweight, portable laboratory. It includes everything your code needs to run: - Operating system tools and libraries - Programming languages and packages - Your actual code and data - Environment settings</p> <p>Key features of containers: - Isolated: What happens in the container stays in the container - Reproducible: Same environment every time you start it - Portable: Works the same way on any computer running Docker - Efficient: Uses fewer resources than traditional virtual machines</p>"},{"location":"docker/#images","title":"Images","text":"<p>An image is the blueprint for a container. It's like a recipe that specifies: - Base operating system - Software to install - Files to include - Commands to run</p> <p>Images are: - Immutable: Once created, they don't change - Layered: Built step by step, making them efficient to store and share - Reusable: Many containers can be created from one image - Shareable: Can be pushed to registries like Docker Hub</p>"},{"location":"docker/#practical-example","title":"Practical Example","text":"<p>Let's look at a real example:</p> <pre><code>docker run hello-world\n</code></pre> <p>This command: 1. Looks for the 'hello-world' image locally 2. If not found, downloads it from Docker Hub 3. Creates a new container from this image 4. Runs the container, which displays a message 5. Exits once complete</p>"},{"location":"docker/#containers-vs-virtual-machines","title":"Containers vs. Virtual Machines","text":"<p>While both provide isolation, they work differently:</p>"},{"location":"docker/#virtual-machines","title":"Virtual Machines:","text":"<ul> <li>Run a complete operating system</li> <li>Require more resources (CPU, memory, storage)</li> <li>Take longer to start</li> <li>Provide stronger isolation</li> </ul>"},{"location":"docker/#containers_1","title":"Containers:","text":"<ul> <li>Share the host's operating system kernel</li> <li>Use fewer resources</li> <li>Start almost instantly</li> <li>Perfect for running individual applications</li> </ul>"},{"location":"docker/#why-use-docker-in-research","title":"Why Use Docker in Research?","text":""},{"location":"docker/#reproducibility","title":"Reproducibility","text":"<ul> <li>Share exact computational environments</li> <li>Eliminate \"works on my machine\" problems</li> <li>Future-proof your analyses</li> <li>Make your research more reproducible</li> </ul>"},{"location":"docker/#collaboration","title":"Collaboration","text":"<ul> <li>Share complex software setups easily</li> <li>Ensure everyone uses the same environment</li> <li>Work across different operating systems</li> <li>Simplify onboarding of new team members</li> </ul>"},{"location":"docker/#efficiency","title":"Efficiency","text":"<ul> <li>Quick setup of new environments</li> <li>Easy testing of different software versions</li> <li>No conflicts between projects</li> <li>Clean separation of different analyses</li> </ul>"},{"location":"docker/#career-development","title":"Career Development","text":"<ul> <li>Industry-standard technology</li> <li>Essential for many data science roles</li> <li>Valuable skill for academic or industry careers</li> <li>Foundation for cloud computing and deployment</li> </ul>"},{"location":"docker/#getting-started","title":"Getting Started","text":"<p>In the next section, we'll start using Docker hands-on. We'll: - Run our first container - Explore basic Docker commands - Learn how to work with images - Understand how to manage data in containers</p> <p>Remember: Docker is a tool to make your research easier and more reproducible. While there's a learning curve, the benefits for scientific computing make it worth the investment.</p>"},{"location":"reproducibility/","title":"Reproducibility","text":"<p>When developing research software, managing dependencies is crucial for reproducibility. There are few different approaches to dependency management and we can think of them like different levels. Each level offers us different amounts of reproducibility with increasing complexity and more significant time cost.</p>"},{"location":"reproducibility/#requirements-files-requirementstxt","title":"Requirements Files (requirements.txt)","text":"<p>The simplest approach to Python dependency management is a <code>requirements.txt</code> file. This is essentially a list of Python packages and their versions:</p> <pre><code>numpy==1.21.0\npandas==1.3.0\nscikit-learn==0.24.2\nmatplotlib==3.4.2\n</code></pre> <p>You can create this file by running: <pre><code>pip freeze &gt; requirements.txt\n</code></pre></p> <p>And someone else can recreate your environment with: <pre><code>pip install -r requirements.txt\n</code></pre></p>"},{"location":"reproducibility/#advantages","title":"Advantages","text":"<ul> <li>Simple and easy to understand</li> <li>Works with pip, Python's package installer</li> <li>Can be generated automatically</li> <li>Widely supported</li> </ul>"},{"location":"reproducibility/#limitations","title":"Limitations","text":"<ul> <li>Only captures Python packages</li> <li>Misses system dependencies</li> <li>No guarantee of binary compatibility</li> <li>Platform-specific packages may fail</li> <li>Can't specify version ranges</li> <li>May include unnecessary dependencies</li> </ul>"},{"location":"reproducibility/#modern-python-projects-pyprojecttoml","title":"Modern Python Projects (pyproject.toml)","text":"<p><code>pyproject.toml</code> is a newer, more sophisticated approach to Python dependency management. It follows modern Python packaging standards (PEP 517/518):</p> <pre><code>[project]\nname = \"myresearch\"\nversion = \"0.1.0\"\ndescription = \"My Research Project\"\nrequires-python = \"&gt;=3.8\"\n\ndependencies = [\n    \"numpy&gt;=1.21.0\",\n    \"pandas~=1.3.0\",\n    \"scikit-learn&gt;=0.24.2,&lt;0.25.0\",\n]\n\n[project.optional-dependencies]\nviz = [\n    \"matplotlib&gt;=3.4.0\",\n    \"seaborn&gt;=0.11.0\",\n]\n</code></pre>"},{"location":"reproducibility/#advantages_1","title":"Advantages","text":"<ul> <li>More flexible version specifications</li> <li>Can define optional dependency groups</li> <li>Includes project metadata</li> <li>Better dependency resolution</li> <li>Can specify build requirements</li> <li>More maintainable</li> </ul>"},{"location":"reproducibility/#limitations_1","title":"Limitations","text":"<ul> <li>Still Python-specific</li> <li>Doesn't handle system dependencies</li> <li>Environment variables not captured</li> <li>No guarantee of system library versions</li> <li>Can't manage non-Python tools</li> </ul>"},{"location":"reproducibility/#conda-and-environmentyml","title":"Conda and Environment.yml","text":"<p>Conda takes a middle ground between simple Python package management and full containerization. It manages both Python and non-Python dependencies, including system-level binary packages:</p> <pre><code>name: myresearch\nchannels:\n  - conda-forge\n  - bioconda\n  - defaults\ndependencies:\n  - python=3.9\n  - numpy=1.21\n  - pandas=1.3\n  - scikit-learn=0.24\n  - pip\n  - gcc\n  - pip:\n    - some-package-only-on-pip==1.0\n</code></pre> <p>We can create an environment from this file with: <pre><code>conda env create -f environment.yml\nconda activate myresearch\n</code></pre></p> <p>and we can export the environment with: <pre><code>conda env export &gt; environment.yml\n</code></pre></p>"},{"location":"reproducibility/#advantages_2","title":"Advantages","text":"<ul> <li>Manages both Python and non-Python packages</li> <li>Handles binary dependencies</li> <li>Cross-platform compatibility</li> <li>Environment isolation</li> <li>Popular in scientific computing</li> <li>Can mix conda and pip packages</li> <li>Solves dependency conflicts well</li> <li>Includes many scientific packages pre-built</li> </ul>"},{"location":"reproducibility/#limitations_2","title":"Limitations","text":"<ul> <li>Slower than pip installation</li> <li>Can be complex to maintain</li> <li>Environment setup can be large</li> <li>Not as complete as Docker (no OS-level isolation)</li> <li>Channel conflicts can occur</li> <li>Still platform-dependent</li> </ul>"},{"location":"reproducibility/#docker-complete-environment-management","title":"Docker: Complete Environment Management","text":"<p>Docker takes a fundamentally different approach by capturing the entire computational environment.</p>"},{"location":"reproducibility/#advantages_3","title":"Advantages","text":"<ul> <li>Captures complete environment:</li> <li>Operating system version</li> <li>System libraries</li> <li>Python installation</li> <li>Python packages</li> <li>System dependencies</li> <li>Environment variables</li> <li>File system setup</li> <li>Highly portable</li> <li>Platform independent</li> <li>Can include non-Python tools</li> <li>Reproducible builds</li> </ul>"},{"location":"reproducibility/#limitations_3","title":"Limitations","text":"<ul> <li>Larger file size</li> <li>Requires Docker installation</li> <li>Learning curve</li> <li>Some performance overhead</li> <li>Hardware-specific issues may still exist</li> </ul>"},{"location":"reproducibility/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Start simple</p> <ul> <li>Begin with <code>requirements.txt</code> during initial development</li> <li>Move to <code>pyproject.toml</code> as project matures</li> <li>Add Docker when needed for full environment control</li> </ul> </li> <li> <p>Version Control</p> <ul> <li>Keep all dependency files in version control</li> <li>Include clear documentation</li> <li>Tag/version important states</li> </ul> </li> <li> <p>Documentation</p> <ul> <li>Document any special requirements</li> <li>Include setup instructions</li> <li>Note known limitations</li> <li>Specify minimum requirements</li> </ul> </li> <li> <p>Testing</p> <ul> <li>Test in clean environments</li> <li>Verify installation procedures</li> <li>Include test data</li> <li>Document expected outputs</li> </ul> </li> </ol> <p>Remember: The goal is to make your research reproducible with minimal friction. Choose the simplest tool that meets your needs, but don't hesitate to use Docker when you need complete environment control.</p>"},{"location":"reproducibility/#conda","title":"Conda?","text":"<p>No.</p>"},{"location":"Basics/dockerhub/","title":"Docker Hub","text":""},{"location":"Basics/hello-world/","title":"Hello Docker!","text":"<p>To get us started let's run a simple Docker container. This is the <code>Hello World</code> of Docker.</p> <p>In your codespace environment, you can essentially maximize the terminal by dragging it to the top of the screen. This will give you more space to work with.</p> <p>In the terminal, run the following command:</p> <pre><code>docker run hello-world\n</code></pre> <p>You should then see something like the following:</p> <pre><code>Unable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\nc1ec31eb5944: Pull complete \nDigest: sha256:d211f485f2dd1dee407a80973c8f129f00d54604d2c90732e8e320e5038a0348\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n ```\n\nLet's have a look at each part in more detail:\n\n```text\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\nc1ec31eb5944: Pull complete\nDigest: sha256:d211f485f2dd1dee407a80973c8f129f00d54604d2c90732e8e320e5038a0348\nStatus: Downloaded newer image for hello-world:latest\n</code></pre> <p>This part of the output shows that Docker was unable to find the <code>hello-world</code> image locally, so it pulled it from the Docker Hub. The <code>hello-world</code> image is a very small image that is used to test that your Docker installation is working correctly.</p> <p><code>latest:</code> is a tag for the image. Tags are used to identify different versions of an image. In this case, the <code>latest</code> tag is used to identify the latest version of the <code>hello-world</code> image.</p> <p><code>c1ec31eb5944: Pull complete</code> is the layer ID of the image that was pulled. Docker images are made up of multiple layers, and each layer is identified by a unique ID. Since the <code>hello-world</code> image is very small, it only has one layer.</p> <p><code>Digest: sha256:d211f485...</code> is a unique hash of the image. This hash is used to uniquely identify the image and its contents.</p> <p>If you try to run the <code>docker run hello-world</code> command again, you should just see the <code>Hello from Docker!</code> message without the other output. This is because Docker has already pulled the <code>hello-world</code> image and cached it locally.</p> <p>The actual content of the container can be seen in the message displayed by the container.</p> <p>It also gives us the following hint:</p> <pre><code>To try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n</code></pre>"},{"location":"Basics/hello-world/#ubuntu-in-a-container","title":"Ubuntu in a Container","text":"<p>So, let's try that next:</p> <pre><code>docker run -it ubuntu bash\n</code></pre> <p>You should now see a new prompt that looks something like this:</p> <pre><code>root@f4b5c7e4b6b4:/#\n</code></pre> <p>This prompt indicates that you are now inside a Docker container running a Ubuntu image. The <code>root@f4b5c7e4b6b4</code> part is the hostname of the container (yours may be different), and the <code>/#</code> part is the command prompt.</p> <p>Here is an overview of the commands we used:</p> <pre><code>docker run   # Base command to create and start a new container\n-i           # Interactive - keep STDIN open (allows you to type into container)\n-t           # Allocate a pseudo-Terminal (gives you the shell prompt)\nubuntu       # The image to use (in this case, official Ubuntu image)\nbash         # The command to run inside container (start a bash shell)\n</code></pre> <p>We can combine tags to make the command shorter: <code>-it</code> is the same as <code>-i -t</code>. Without <code>-it</code>:</p> <ul> <li><code>-i</code> only: You can send input but display will be weird</li> <li><code>-t</code> only: You get nice formatting but can't type input</li> <li>neither: Container runs the command and exits unless it has a foreground process</li> </ul> <p>A \"bash shell\" is the command line interface (CLI). It so happens that if we run:</p> <p><pre><code>docker run -it ubuntu\n</code></pre> we'll also get a bash shell anyway, because this is the default command for the Ubuntu image. However, you can also do:</p> <pre><code>docker run -it ubuntu sh\n</code></pre> <p>to get a simple shell instead of bash. You can also do</p> <p><pre><code>docker run -it ubuntu zsh\n</code></pre> to get the interface that macOS uses. It is not available for this image, but you can install it in your own images. </p> <p>When we are inside the container, if we run:</p> <pre><code>cat /etc/os-release\n</code></pre> <p>You should see the following output:</p> <pre><code>PRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04.1 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=noble\nLOGO=ubuntu-logo\n</code></pre> <p>confirming that you are indeed running a Ubuntu container. This container does not have any additional software installed, so you have a clean Ubuntu environment to work with. To exit the container, you can type <code>exit</code> and press <code>Enter</code>.</p>"},{"location":"Basics/hello-world/#python-in-a-container","title":"Python in a Container","text":"<p>Let's grab a python container:</p> <pre><code>docker run -it python bash\n</code></pre> <p>We are now inside a docker container with python, and we can run python commands:</p> <pre><code>python --version\nPython 3.13.0\n</code></pre> <p>We can also run python and play around with it:</p> <pre><code>python\n</code></pre> <pre><code>&gt;&gt;&gt; print(\"Hello, Docker!\")\nHello, Docker!\n&gt;&gt;&gt; exit()\n</code></pre> <p>You can directly access the Python REPL while running the container:</p> <pre><code>docker run -it python python\n</code></pre> <p>If you exit the REPL in the usual way, then you will also exit the container.</p>"},{"location":"Basics/hello-world/#seeing-the-containers-and-images","title":"Seeing the Containers and Images","text":"<p>In order to see a list of images that we have pulled, we can run:</p> <p><pre><code>docker images\n</code></pre> and the output should be something like: <pre><code>REPOSITORY    TAG                  IMAGE ID       CREATED         SIZE\npython        latest               c41ea8273365   4 weeks ago     1.02GB\npython        3.12-slim-bookworm   668757ec60ef   4 weeks ago     124MB\nubuntu        latest               fec8bfd95b54   5 weeks ago     78.1MB\nhello-world   latest               d2c94e258dcb   18 months ago   13.3kB\n</code></pre></p> <p>To see a list of all containers, we run: <pre><code>docker ps -a\n</code></pre></p> <p>You should see something like this: <pre><code>CONTAINER ID   IMAGE                       COMMAND    CREATED          STATUS                        PORTS     NAMES\n5cb8b1bbe52f   ubuntu                      \"bash\"     13 minutes ago   Exited (127) 13 minutes ago             wizardly_cartwright\n80040792ac55   python:3.12-slim-bookworm   \"bash\"     14 minutes ago   Exited (0) 13 minutes ago               heuristic_kilby\n42129b1076cd   python                      \"python\"   28 minutes ago   Exited (0) 20 minutes ago               peaceful_raman\n112c227987a6   python                      \"zsh\"      28 minutes ago   Created                                 confident_lalande\n724386298bc2   python                      \"sh\"       28 minutes ago   Exited (0) 28 minutes ago               nervous_brahmagupta\n4e490eb53aaf   python                      \"bash\"     34 minutes ago   Exited (0) 28 minutes ago               quirky_bohr\n21eea7f7d3b4   ubuntu                      \"bash\"     35 minutes ago   Exited (0) 34 minutes ago               admiring_payne\n19379f07e484   hello-world                 \"/hello\"   35 minutes ago   Exited (0) 35 minutes ago               adoring_keller\n</code></pre></p> <p>note the colourful names...</p> <p>We can remove containers with:</p> <p><pre><code>docker rm &lt;container_id&gt;\n</code></pre> and all unused containers with:</p> <pre><code>docker container prune\n</code></pre> <p>Remove all images with:</p> <pre><code>docker rmi -f $(docker images -aq)\n</code></pre> <p>Now if you run <code>docker ps -a</code> you should see an empty list.</p>"},{"location":"Basics/hello-world/#naming-containers","title":"Naming containers","text":"<p>You might have noticed that the containers have random names, and that if you want to stop them, you have to use the ID, which is cumbersome. So instead, you can name the container when you run it:</p> <pre><code>docker run -it --name mycontainer -it python bash\n</code></pre> <p>Now I can remove the container with:</p> <pre><code>docker rm mycontainer\n</code></pre>"},{"location":"Basics/hello-world/#preserving-information","title":"Preserving information","text":"<p>Let's run the python container again</p> <pre><code>docker run -it python bash\n</code></pre> <p>and try to create a directory:</p> <pre><code>cd home\nmkdir mydir\n</code></pre> <p>If you run <code>ls</code> you should see the <code>mydir</code> directory. Now see what happens when you close down the container and start it again:</p> <pre><code>docker run -it python bash\ncd home\nls\n</code></pre> <p>There is nothing there! What is going on? First we need to see exactly why this is happening. Run the <code>docker ps -a</code> command, and you should see the following: <pre><code>CONTAINER ID   IMAGE     COMMAND   CREATED          STATUS                      PORTS     NAMES\n0b89d0ef62fa   python    \"bash\"    17 seconds ago   Exited (0) 4 seconds ago              vigorous_gould\n90ff3f1f1085   python    \"bash\"    34 seconds ago   Exited (0) 25 seconds ago             distracted_bohr\n</code></pre></p> <p>So we have actually created two containers, and we are not using the same one. This is because when we run the <code>docker run</code> command, we are creating a new container each time. This is why the changes we made in the first container are not present in the second container.</p> <p>So instead I can restart my previous container and attach to it:</p> <pre><code>docker start -ai distracted_bohr\n</code></pre> <p>Now when I change into the <code>home</code> directory and run <code>ls</code>, I should see the <code>mydir</code> directory. The above command is saying \"start the container <code>distracted_bohr</code> and attach to it interactively\".</p> <p>Generally speaking, we do not want to store data in a container. This includes creating files, directories, and databases. If we store files inside the container, they will be lost when the container is stopped or removed:</p> <ol> <li> <p>Persistence Beyond the Lifecycle of the Container Containers are ephemeral by design. If you need to update or recreate a container (e.g., pulling a new image), the data stored directly in the container is lost unless explicitly backed up. Mounted volumes persist independently of the container lifecycle, ensuring your data is safe even if the container is removed.</p> </li> <li> <p>Ease of Data Sharing Mounted volumes allow data to be shared between multiple containers. For example, if you have one container for a database and another for a web application, both can share a mounted volume for logs or configurations.</p> </li> <li> <p>Integration with Host Filesystem With a mounted volume, you can directly edit files from your host system (e.g., code tracked in Git), and changes will be reflected in the container in real-time. This makes development workflows more efficient and eliminates the need for repeated docker cp commands.</p> </li> <li> <p>Simplified Version Control with Git If you're using Git, you likely want your working directory (e.g., /app in the container) to correspond to your Git repository on the host. Mounting the directory ensures that any changes made in the container are tracked by Git on the host, simplifying version control and collaboration.</p> </li> <li> <p>Backup and Portability Mounted volumes are easier to back up and migrate. You can copy a directory from your host system for safekeeping or move it to another machine. Data stored inside a container is harder to extract and manage outside of Docker.</p> </li> <li> <p>Security and Isolation Using mounted volumes can help isolate the container's internal state from persistent data. This separation reduces the risk of accidental data loss due to container mismanagement.</p> </li> </ol> <p>This is why containers are often used for running stateless applications that do not need to store data between runs. So how can we store data in a container? We can use volumes.</p>"},{"location":"Basics/volumes/","title":"Volumes","text":"<p>We just saw that containers are stateless - when we created a directory and then started a new container, our directory was gone. This is actually a feature, not a bug! It ensures that every time someone runs your container, they start with the exact same environment. But what if we do need to save data or share files between our computer and the container?</p>"},{"location":"Basics/volumes/#introducing-volumes","title":"Introducing Volumes","text":"<p>Volumes are how we share files and folders between our computer (the \"host\") and the container. Think of them like a shared folder that both can see and modify.</p> <p>Let's try this:</p> <pre><code># Create a folder for our work\nmkdir myproject\ncd myproject\n\n# Create a simple Python script\necho \"print('Hello from the host!')\" &gt; script.py\n\n# Run Python container with current directory mounted\ndocker run -v $(pwd):/work python:3.9 python /work/script.py\n</code></pre> <p>Let's break down what happened: - <code>-v $(pwd):/work</code> creates a volume:   - <code>$(pwd)</code> is our current directory on the host   - <code>:/work</code> is where it appears in the container   - The files are the same in both places!</p>"},{"location":"Basics/volumes/#persistent-data","title":"Persistent Data","text":"<p>Now let's see how volumes solve our earlier problem:</p> <pre><code># Run container with mounted volume\ndocker run -it -v $(pwd):/work python:3.9 bash\n\n# Inside container:\ncd /work\nmkdir data\necho \"This will persist!\" &gt; data/note.txt\nexit\n\n# Back on host, check the files:\nls data\ncat data/note.txt\n</code></pre> <p>The files we created in the container are right there on our computer! This is crucial for: - Saving analysis results - Working with data files - Developing code - Storing configuration</p>"},{"location":"Basics/volumes/#common-volume-use-cases","title":"Common Volume Use Cases","text":"<ol> <li> <p>Code Development <pre><code>docker run -it -v $(pwd):/code python:3.9 bash\n</code></pre></p> </li> <li> <p>Data Analysis <pre><code>docker run -v $(pwd)/data:/data -v $(pwd)/notebooks:/notebooks jupyter/datascience-notebook\n</code></pre></p> </li> <li> <p>Results Output <pre><code>docker run -v $(pwd)/results:/results myanalysis\n</code></pre></p> </li> </ol>"},{"location":"Basics/volumes/#important-volume-tips","title":"Important Volume Tips","text":"<ol> <li> <p>Use Absolute Paths: While <code>$(pwd)</code> works for current directory, absolute paths are more reliable: <pre><code>docker run -v /Users/me/project:/work python:3.9\n</code></pre></p> </li> <li> <p>Read-Only Volumes: Add <code>:ro</code> to prevent container from modifying host files: <pre><code>docker run -v $(pwd):/work:ro python:3.9\n</code></pre></p> </li> <li> <p>Multiple Volumes: You can mount multiple volumes: <pre><code>docker run \\\n  -v $(pwd)/data:/data \\\n  -v $(pwd)/config:/config \\\n  -v $(pwd)/results:/results \\\n  python:3.9\n</code></pre></p> </li> </ol>"},{"location":"Basics/volumes/#best-practices-for-research","title":"Best Practices for Research","text":"<ol> <li> <p>Organize Your Mounts: <pre><code>project/\n  \u251c\u2500\u2500 data/         # Mount as /data\n  \u251c\u2500\u2500 notebooks/    # Mount as /notebooks\n  \u251c\u2500\u2500 scripts/      # Mount as /scripts\n  \u2514\u2500\u2500 results/      # Mount as /results\n</code></pre></p> </li> <li> <p>Document Your Volumes: <pre><code># Run analysis with required volumes\ndocker run \\\n  -v $(pwd)/data:/data:ro      # Input data (read-only)\n  -v $(pwd)/results:/results    # Analysis output\n  -v $(pwd)/config:/config:ro   # Configuration files\n  myanalysis\n</code></pre></p> </li> <li> <p>Consider Data Size:</p> </li> <li>Large datasets might be better referenced externally</li> <li>Consider using data subsets for development</li> <li>Document data requirements clearly</li> </ol> <p>Next, we'll look at creating our own images with Dockerfiles, so we can package up our entire research environment for others to use.</p>"},{"location":"Building-your-own-images/","title":"Introduction to Dockerfiles","text":"<p>A Dockerfile is a text file that contains instructions for building a Docker image. Think of it as a recipe that tells Docker exactly how to create a container image step by step. Each instruction in the Dockerfile adds a new \"layer\" to the image, making it a powerful way to create reproducible computing environments.</p>"},{"location":"Building-your-own-images/#key-concepts","title":"Key Concepts","text":"<p>Base Image: Every Dockerfile starts with a base image, specified by the <code>FROM</code> instruction. This is like choosing your starting point - it could be a minimal Linux distribution, or a pre-configured Python environment. The base image provides the foundation for your container.</p> <p>Layers: Docker images are built in layers. Each instruction in your Dockerfile creates a new layer. These layers are cached, which means if you rebuild your image and nothing has changed in a particular layer, Docker will reuse the cached version, making builds faster.</p> <p>Build Context: When you build a Docker image, Docker sends all the files in the current directory (and subdirectories) to the Docker daemon. This is called the build context. The <code>.dockerignore</code> file can be used to exclude files you don't want to include.</p>"},{"location":"Building-your-own-images/#common-instructions","title":"Common Instructions","text":"<p>Dockerfiles use a specific set of instructions, each serving a different purpose:</p> <ul> <li><code>FROM</code> - Sets the base image</li> <li><code>WORKDIR</code> - Sets the working directory</li> <li><code>COPY</code> and <code>ADD</code> - Copy files into the image</li> <li><code>RUN</code> - Executes commands</li> <li><code>ENV</code> - Sets environment variables</li> <li><code>EXPOSE</code> - Documents which ports the container will listen on</li> <li><code>CMD</code> - Sets the default command to run when starting a container</li> </ul>"},{"location":"Building-your-own-images/#best-practices","title":"Best Practices","text":"<ol> <li>Use specific base image versions to ensure reproducibility</li> <li>Minimize the number of layers for efficiency</li> <li>Place instructions that change frequently at the end of the Dockerfile</li> <li>Use a .dockerignore file to exclude unnecessary files</li> <li>Run applications as a non-root user for security</li> <li>Use multi-stage builds for smaller production images</li> </ol>"},{"location":"Building-your-own-images/dockerfiles/","title":"Building your own images","text":""},{"location":"Building-your-own-images/dockerfiles/#project-overview","title":"Project overview","text":"<p>In this section we will build our own images using Dockerfiles. In order to demonstrate the process, we will have some example project files. In the <code>cancer-prediction</code> directory, we have the following:</p> <pre><code>\u251c\u2500\u2500 cancer_prediction\n\u2502   \u251c\u2500\u2500 cancer_model.py\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u2502   \u251c\u2500\u2500 breast_cancer.csv\n\u2502   \u2502   \u251c\u2500\u2500 breast_cancer_test.csv\n\u2502   \u2502   \u2514\u2500\u2500 breast_cancer_train.csv\n\u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u2514\u2500\u2500 cancer_model.pkl\n\u2502   \u2514\u2500\u2500 notebook.ipynb\n\u2514\u2500\u2500 requirements.txt\n</code></pre> <p>We might want our collaborators to be able to run all of the code in the <code>cancer-prediction</code> directory without having to install all of the dependencies. We can create a Dockerfile to build an image that contains all of the dependencies and code needed to run the project.</p> <p>You should fork this repository (include all branches, not just <code>main</code>). Then create a new Codespace on the <code>start</code> branch. You should then see the above directory plus some other stuff like a LICENSE file and a README.md file.</p> <p>This overview sets us up to dive deeper into each of these concepts and see how they work in practice with our machine learning project.</p>"},{"location":"Building-your-own-images/dockerfiles/#our-dockerfile","title":"Our Dockerfile","text":"<p>Here is the Dockerfile:</p> <pre><code># Start from an official Python base image\nFROM python:3.11-slim-bookworm\n\n# Install git and clean up apt cache in the same layer\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends git &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# Set working directory in the container\nWORKDIR /workspace\n\n# Copy requirements first to leverage Docker cache\nCOPY requirements.txt .\n\n# Install dependencies - combine commands to reduce layers\nRUN pip install --no-cache-dir \\\n    jupyterlab \\\n    jupyterlab-git \\\n    httpx==0.27.2 \\\n    -r requirements.txt\n\n# Copy the entire project\nCOPY . .\n\n# Expose the port Jupyter will run on\nEXPOSE 8888\n\n# Start Jupyter Lab from the cancer_prediction directory\nWORKDIR /workspace/cancer-prediction\nCMD [\"jupyter\", \"lab\", \"--ip=0.0.0.0\", \"--port=8888\", \"--no-browser\", \"--LabApp.token=''\", \"--LabApp.password=''\"]\n</code></pre> <p>Let's walkthrough the Dockerfile.</p> <p><code>FROM python:3.11-slim-bookworm</code></p> <ul> <li>Starts with official Python 3.11 image</li> <li>'slim-bookworm' means minimal Debian Bookworm-based image, reducing container size</li> <li>Alternative to full image which includes many unnecessary packages</li> </ul> <p><code>RUN apt-get update &amp;&amp; ...</code></p> <ul> <li>Installs git for version control</li> <li>Cleans up apt cache to reduce image size</li> <li>Combines commands to reduce layers</li> </ul> <p><code>WORKDIR /workspace</code></p> <ul> <li>Creates and sets the working directory to /workspace</li> <li>All subsequent commands will run from this directory</li> <li>Standard practice for development containers</li> </ul> <p><code>COPY requirements.txt .</code></p> <ul> <li>Copies only requirements.txt first</li> <li>Helps with build caching - if requirements don't change, cache this layer</li> <li>The '.' means copy to current WORKDIR</li> </ul> <p><code>RUN pip install --no-cache-dir \\ jupyterlab \\ -r requirements.txt</code></p> <ul> <li>Installs Python packages</li> <li><code>--no-cache-dir</code> reduces image size by not caching pip downloads</li> <li>Combines installations in one RUN to create single layer</li> <li>Backslashes allow multiple lines for readability</li> </ul> <p><code>COPY . .</code></p> <ul> <li>Copies all remaining project files</li> <li>First '.' means everything in build context</li> <li>Second '.' means copy to current WORKDIR</li> <li>Done after requirements for better caching</li> </ul> <p><code>USER jupyter</code></p> <ul> <li>Switches to non-root user</li> <li>All subsequent commands run as this user</li> </ul> <p><code>EXPOSE 8888</code></p> <ul> <li>Documents that container uses port 8888</li> <li>Doesn't actually open port - that's done at runtime</li> <li>JupyterLab's default port</li> </ul> <p><code>WORKDIR /workspace/cancer_prediction</code></p> <ul> <li>Changes working directory again</li> <li>Ensures Jupyter starts in project directory</li> </ul> <p><code>CMD [\"jupyter\", \"lab\", \"--ip=0.0.0.0\" ...]</code></p> <ul> <li>Command to run when container starts</li> <li><code>--ip=0.0.0.0</code> allows external connections</li> <li><code>--no-browser</code> since running in container</li> <li>Empty token/password for workshop access</li> </ul>"},{"location":"Building-your-own-images/dockerfiles/#building-the-image","title":"Building the image","text":"<p>To build the image, run the following command in the terminal:</p> <pre><code>docker build -t cancer-prediction .\n</code></pre> <p>This command builds the image using the Dockerfile in the current directory and tags it with the name <code>cancer-prediction</code>.</p>"},{"location":"Building-your-own-images/dockerfiles/#running-the-container","title":"Running the container","text":"<p>To run the container, use the following command:</p> <pre><code>docker run -p 8888:8888 cancer-prediction\n</code></pre> <p>You should see the Jupyter Lab URL open in the browser. If you run something in the notebook and save it, the changes will not persist in the container. To achieve this, you will need to mount your volume directory when running the container:</p> <pre><code>docker run -p 8888:8888 -v $(pwd):/workspace cancer-prediction\n</code></pre>"},{"location":"Building-your-own-images/dockerhub/","title":"Docker Repositories","text":"<p>But where to store your images so that other people can use them? We have two options:</p> <ol> <li>Docker Hub: The default registry for Docker images. It is free to use for public repositories, but you have to pay for private repositories.</li> <li>GitHub Container Registry: GitHub's own registry for Docker images. It is free to use for public and private repositories.</li> </ol> <p>We will cover both options here.</p>"},{"location":"Building-your-own-images/dockerhub/#docker-hub","title":"Docker Hub","text":"<p>When we pulled those basic Ubuntu and Python images, we were actually pulling them from Docker Hub. Docker Hub is the default registry for Docker images.</p> <p>First, we go to our docker hub repository tab and create a new repository. We can name it anything we want. For this example, we will name it <code>cancer-prediction</code>.</p> <p>We then need to login in our command line:</p> <pre><code>docker login --username=yourhubusername\n</code></pre> <p>You will then be prompted for your password. We can now run:</p> <pre><code>docker push acceleratescience/cancer-prediction:latest\n</code></pre> <p>When you navigate to your repository on Docker Hub, you should see your image there.</p> <p>You could now pull this image and it should run with:</p> <pre><code>docker run -p 8888:8888 acceleratescience/cancer-prediction:latest\n</code></pre> <p>Success! You have now built and pushed your own Docker image to Docker Hub, downloaded it, and run it. If you package up your research in this way, other people will be able to do the same thing. And notice that everything inside the container just works, even though it was built on your machine.</p>"},{"location":"Building-your-own-images/dockerhub/#automate-this-process","title":"Automate this process","text":"<p>Ideally, we would want to actually automate this process of pushing new versions to Docker Hub. We can do this by setting up a GitHub action. We will also use this opportunity to push to the GitHub Container Registry.</p>"},{"location":"Building-your-own-images/dockerhub/#the-github-action","title":"The GitHub Action","text":"<p>Create a new file in your repository at <code>.github/workflows/docker-publish.yml</code> with the following content:</p> <pre><code># This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# GitHub recommends pinning actions to a commit SHA.\n# To get a newer version, you will need to update the SHA.\n# You can also reference a tag or branch, but the action may change without warning.\n\nname: Publish Docker image\n\non:\n  release:\n    types: [published]\n\njobs:\n  push_to_registry:\n    name: Push Docker image to Docker Hub\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n      attestations: write\n      id-token: write\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v4\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\n        with:\n          images: my-docker-hub-namespace/my-docker-hub-repository\n\n      - name: Build and push Docker image\n        id: push\n        uses: docker/build-push-action@3b5e8027fcad23fda98b2e3ac259d8d67585f671\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n</code></pre> <p>The important thing here is to replace <pre><code>with:\n  images: my-docker-hub-namespace/my-docker-hub-repository\n</code></pre> with you actual Docker Hub user name and the repo name (which is cancer-prediction in our case).</p> <p>You will also need to add your Docker Hub username and password as secrets in your repository. You can do this by going to your repository, clicking on settings, and then secrets.</p>"},{"location":"Building-your-own-images/dockerhub/#create-a-new-release","title":"Create a new release","text":"<p>Head back over to GitHub and create a new release. You can do this by clicking on the releases tab and then clicking on the \"Draft a new release\" button. You can name the release anything you want. You can also add a description if you want. You should add a tag, such as <code>v0.0.1</code> and make sure you are targeting the correct branch. In this case, we are on the <code>start</code> branch.</p> <p>Finally, click \"Publish release\". You should now see your GitHub action running. If you navigate to the actions tab, you can see the progress of the action. If it is successful, you should see your image on Docker Hub.</p>"},{"location":"Building-your-own-images/dockerhub/#adding-the-github-container-registry","title":"Adding the GitHub Container Registry","text":"<p>We can reuse most of what we have already built, and add a few more lines:</p> <pre><code># This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# GitHub recommends pinning actions to a commit SHA.\n# To get a newer version, you will need to update the SHA.\n# You can also reference a tag or branch, but the action may change without warning.\n\nname: Publish Docker image\n\non:\n  release:\n    types: [published]\n\njobs:\n  push_to_registries:\n    name: Push Docker image to multiple registries\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n      attestations: write\n      id-token: write\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v4\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\n        with:\n          images: |\n            acceleratescience/cancer-prediction\n            ghcr.io/${{ github.repository_owner }}/cancer-prediction\n\n      - name: Build and push Docker images\n        id: push\n        uses: docker/build-push-action@3b5e8027fcad23fda98b2e3ac259d8d67585f671\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64,linux/arm64\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n</code></pre>"},{"location":"Building-your-own-images/dockerhub/#multiplatform-builds","title":"Multiplatform builds","text":"<p>Notice at the end here, we have added:  <pre><code>platforms: linux/amd64,linux/arm64\n</code></pre> This is because the GitHub Container Registry supports multiple architectures. A multi-platform build refers to a single build invocation that targets multiple different operating system or CPU architecture combinations. When building images, this lets you create a single image that can run on multiple platforms, such as <code>linux/amd64</code>, <code>linux/arm64</code>, and <code>windows/amd64</code></p> <p>Although Docker for the most part solves the \"it works on my machine\" problem by packaging applications and their dependencies into containers. This actually only solves part of the problem. Containers share the host kernel, which means that the code that's running inside the container must be compatible with the host's architecture. This means that you cannot run a linux/amd64 container on an arm64 host (without using emulation), or a Windows container on a Linux host.</p> <p>Multi-platform builds solve this problem by packaging multiple variants of the same application into a single image. This enables you to run the same image on different types of hardware, such as development machines running x86-64 or ARM-based Amazon EC2 instances in the cloud, without the need for emulation.</p> <p>Multiplatform builts typically take longer to create, but they are worth it for the flexibility they provide - some people may have MacOS and some may be using Linux.</p>"},{"location":"Building-your-own-images/hello-world/","title":"Hello, world!","text":"<p>As a reminder, when we ran the <code>hello-world</code> image, we saw the following output: <pre><code>$ docker run hello-world\n</code></pre> <pre><code>Hello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n</code></pre></p> <p>As a simple first step, let's try and recreate this image from scratch. We will create a new directory called <code>hello-world</code> and create a new file called <code>Dockerfile</code> inside it. The contents of the <code>Dockerfile</code> will be as follows: <pre><code># Use a minimal base image\nFROM alpine:latest\n\n# Create a simple script that will be our executable\nCOPY hello.sh /\nRUN chmod +x /hello.sh\n\n# Set the script as our container's entry point\nENTRYPOINT [\"/hello.sh\"]\n</code></pre></p> <p>and also create a new file called <code>hello.sh</code> with the following contents: <pre><code>#!/bin/sh\n\necho \"Hello from your custom Docker container!\"\necho \"This message demonstrates that you've successfully:\"\necho \"\"\necho \" 1. Built a custom Docker image from a Dockerfile\"\necho \" 2. Created a container from that image\"\necho \" 3. Executed a script inside the container\"\necho \" 4. Had the output streamed back to your terminal\"\necho \"\"\necho \"Things this example demonstrates:\"\necho \" - Using a base image (alpine:latest)\"\necho \" - Copying files into a container\"\necho \" - Setting file permissions\"\necho \" - Using ENTRYPOINT to define container behavior\"\necho \"\"\necho \"Try these next steps:\"\necho \" 1. Look at the Dockerfile to see how this works\"\necho \" 2. Modify the script to print different messages\"\necho \" 3. Rebuild the image to see your changes\"\necho \"\"\necho \"Happy Dockerizing! \ud83d\udc33\"\n</code></pre></p> <p>We can now run <pre><code>docker build -t my-hello-world .\n</code></pre></p> <p>and then <pre><code>docker run my-hello-world\n</code></pre></p> <p>and we should see the following output: <pre><code>Hello from your custom Docker container!\nThis message demonstrates that you've successfully:\n\n 1. Built a custom Docker image from a Dockerfile\n 2. Created a container from that image\n 3. Executed a script inside the container\n 4. Had the output streamed back to your terminal\n\nThings this example demonstrates:\n - Using a base image (alpine:latest)\n - Copying files into a container\n - Setting file permissions\n - Using ENTRYPOINT to define container behavior\n\nTry these next steps:\n 1. Look at the Dockerfile to see how this works\n 2. Modify the script to print different messages\n 3. Rebuild the image to see your changes\n\nHappy Dockerizing! \ud83d\udc33\n</code></pre></p> <p>Let's try something harder...</p>"},{"location":"Home/LICENSE/","title":"License","text":"<pre><code>                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. &lt;https://fsf.org/&gt;\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    &lt;one line to give the program's name and a brief idea of what it does.&gt;\n    Copyright (C) &lt;year&gt;  &lt;name of author&gt;\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    &lt;program&gt;  Copyright (C) &lt;year&gt;  &lt;name of author&gt;\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n&lt;https://www.gnu.org/licenses/&gt;.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n&lt;https://www.gnu.org/licenses/why-not-lgpl.html&gt;.\n</code></pre>"},{"location":"Home/about/","title":"About us","text":"<p>The Accelerate Programme for Scientific Discovery pursues research at the interface of AI and the sciences, generating new scientific insights and developing AI methods that can be deployed to advance scientific knowledge. This research is carried out in partnership with a community of scientists and AI specialists passionate about the use of AI to benefit science and society.</p> <p>As part of our work, we aim to put together some resources to help researchers in developing software.</p> <p>For more details please visit Our Website.</p>"},{"location":"intro/","title":"Introduction to Docker","text":"<p>In this section we explore some common problems with using Python for scientific computing and how Docker can help us solve them.</p>"},{"location":"intro/introdocker/","title":"Our first steps with Docker","text":"<p>Here we will get up and running with Docker, and introduce some basic commands.</p>"},{"location":"intro/introdocker/#installing-docker","title":"Installing Docker","text":"<p>You can install Docker from the official website. Your experience may vary depending on your operating system. Take careful note of the requirements, especially for Windows - you will need the Windows Subsystem for Linux (WSL) enabled, which should come as standard on Windows 10 and later.</p> <p>For windows users, we will be working in WSL terminal. This means you will need to setup VSCode to be using the WSL terminal by default. You can do this by opening the command palette (Ctrl+Shift+P) and typing <code>Terminal: Select Default Shell</code>. You can then select <code>WSL Bash</code> from the list.</p> <p>For MacOS and Linux users, your lives are easier. You can just use the terminal as normal. From here on out, we'll assume you're using the terminal.</p>"},{"location":"intro/introdocker/#running-your-first-container","title":"Running your first container","text":"<p>Once you have Docker installed, you can run your first container. Open a terminal and type the following command:</p> <pre><code>docker run hello-world\n</code></pre> <p>This will download the <code>hello-world</code> image from the Docker Hub and run it. You should see the following:</p> <pre><code>Unable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n478afc919002: Pull complete\nDigest: sha256:a26bff933ddc26d5cdf7faa98b4ae1e3ec20c4985e6f87ac0973052224d24302\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (arm64v8)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n</code></pre> <p>If you check out the Docker Desktop, you will now see that the <code>hello-world</code> image is downloaded and running. To see a list of images, run</p> <pre><code>docker image ls -a\n</code></pre> <p>and to see a list of containers, run</p> <pre><code>docker container ls -a\n</code></pre>"},{"location":"intro/introdocker/#running-an-interactive-container","title":"Running an interactive container","text":"<p>Now here is where things get really interesting. Run the following command:</p> <pre><code>docker run -it ubuntu\n</code></pre> <p>You should something like the following:</p> <pre><code>root@ba2346677656:/#\n</code></pre> <p>Now enter,</p> <pre><code>cat /etc/os-release\n</code></pre> <p>You should see something like:</p> <pre><code>PRETTY_NAME=\"Ubuntu 24.04 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=noble\nLOGO=ubuntu-logo\n</code></pre> <p>So we have learned that we are no longer using the host machine command line, but in a container running Ubuntu 24.04 LTS. This is a powerful concept, as it allows us to run software in a controlled environment, without having to worry about dependencies!</p> <p>We can stop the container by typing <code>exit</code>, but we will keep it running for now.</p> <p>Create a new directory called <code>workspace</code>:</p> <pre><code>mkdir workspaces &amp;&amp; cd workspaces.\n</code></pre> <p>Open up VSCode and install the Remote Development extension. Once this is installed, connect to the container that is now running. We now have a fully functional Ubuntu environment running in a container and accessible from VSCode!</p> <p>Just to really hammer home how powerful this is, we now no longer have to worry about installing software on our host machine. We don't have to worry about managing dependencies and environments, because this IS our environment!</p> <p>Through this workshop we will build a small machine learning project in this container and deploy it on a remote GPU. We will learn how to make our own containers, upload them to Docker Hub and build off of them. We will also learn how to use Docker in a CI/CD pipeline.</p>"},{"location":"intro/introdocker/#further-reading","title":"Further reading","text":"<ul> <li> <p> CI/CD - Testing resources</p> <p>Information on GitHub Workflows</p> </li> </ul>"},{"location":"intro/why/","title":"Why Docker?","text":"<p>So far, you are likely using one of three methods to manage you Python projects:</p> <ol> <li>conda</li> <li>venv or pyenv</li> <li>absolutely nothing and just using <code>pip install</code> in your base Python environment</li> </ol> <p>If you're using 3, then you've likely already run into the following problems:</p> <ul> <li>Dependency hell</li> <li>Reproducibility issues</li> <li>Incompatibility with other operating systems</li> </ul> <p>Scenario</p> <p>You start a new project, <code>my-project-1</code>, and install package X. When you try to import package X, you realize that X actually needs another package to run successfully, called Y. You install that too. You go about your work, and all is well!</p> <p>A few months later, you start a new project, <code>my-project-2</code>, and install package Z. You import package Z, and go about your work, and all is well!</p> <p>A few months later, you start working on <code>my-project-1</code> again. You open your Jupyter notebook and try to run the first cell but it fails! Panic! When you try and import package X, you are getting the same error as before and you need to install package Y again! But why!? You already did this! So you install package Y again, and go about your work. All is well again!</p> <p>After spending a few hours on <code>my-project-1</code> you switch back over to <code>my-project-2</code>. You open your notebook and run the first cell, but it fails when trying to import package Z! Panic! Package Z claims that it cannot import package Y! But why!? You already installed package Y! Twice! So you install package Y again, and try to run the first cell, but it fails! Panic! What is going on!? You uninstall package Z, and reinstall it again, and now your first cell works! Excellent! You open up your other notebook where you are working on <code>my-project-1</code>, and rerun the imports.</p> <p>They fail.</p> <p>You sell your worldly possessions and move to Tibet.</p> <p>In the scenario above, what you didn't realize is that when you installed package Y after installing X, using <code>pip install Y</code>, you were installing the lastest version, perhaps v1.2.23. But then, when you installed package Z, it also needed package Y, but it needed v1.1.13. So, when you installed Z, it downgraded Y to v1.1.13. The difference between these two versions was enough to completely break package X. You have taken your first steps down into dependency hell.</p>"},{"location":"intro/why/#the-above-problem-is-easy-to-fix","title":"The above problem is easy to fix","text":"<p>Conda and venv provide an easy way to create standalone Python versions that are isolated from your base Python installation. This means that you can install different versions of packages in different environments, and they won't interfere with each other. This is a great way to avoid the above problem.</p> <p>However, there are still some issues with this approach. When working collaboratively, it is usually impractical to share your entire environment with your collaborators. This is because your environment is likely to be quite large, and may contain sensitive information. This means that your collaborators will need to recreate your environment on their own machine, and install all the necessary packages. This can be a time-consuming process, and can lead to errors if not done correctly. This can be made easier by using a combination of <code>requirements.txt</code> and <code>environment.yml</code> files, but this is still not foolproof.</p> <p>What if you want to share some code with someone who doesn't even have python installed? Or perhaps onboard new students without having to spend hours setting up their environments?</p> <p>This is where Docker comes in.</p> <p>Docker allows you to create lightweight, portable, self-sufficient containers that can run on any machine that has Docker installed. This means that you can package up your entire environment, including your code, and share it with anyone. They can then run your code in the exact same environment that you developed it in, without having to worry about installing packages, or setting up their environment.</p>"},{"location":"multi_1/subpage_1/","title":"Subpage 1","text":""},{"location":"multi_1/subpage_1/#hello-this-is-a-subpage","title":"Hello, this is a subpage","text":"<p>It really is that simple. Like Poetry.</p>"},{"location":"multi_1/subpage_1/#further-reading","title":"Further reading","text":"<ul> <li> <p> Publishing resources</p> <p>Information on PyPI, Test PyPI, Python packaging and publishing with Poetry</p> </li> </ul>"},{"location":"multi_1/subpage_2/","title":"Subpage 2","text":"<p>There are a few popular ways to publish documentation for your project. Here, we will use MkDocs, but another popular framework is Read the Docs. MkDocs is highly customizable, has good support, and is used by many companies around the world. This site was created with Material for MkDocs.</p>"},{"location":"multi_1/subpage_2/#multi-page-1","title":"Multi Page 1","text":"<p>And that's about it.</p>"},{"location":"multi_1/subpage_2/#further-reading","title":"Further reading","text":"<ul> <li> <p> Documentation resources</p> <p>Information on PEP style guides, docstring conventions and type hints, as well as popular documentation frameworks</p> </li> </ul>"},{"location":"resources/","title":"Resources","text":"<ul> <li> <p> Slides</p> <p>Here you can find the slides for the course material</p> </li> </ul> <ul> <li> <p> Resources</p> <p>Each section contains a summary of further resources, but here they are all collected for convenience</p> </li> </ul>"},{"location":"resources/references/","title":"References","text":"<p>Here you can find the relevant references used in the sections, and some additional resources. The examples here are for a course in packaging and testing Python code. Your titles should match the page sections, and the links should be to the official documentation or other reputable sources.</p>"},{"location":"resources/references/#setting-up","title":"References","text":"<p>Python - Creation of virtual environments</p> <p>GitHub - About Git</p> <p>GitHub - Introduction to GitHub</p> <p>GitHub - Codespaces</p> <p>GitHub - Copilot</p> <p>GitHub - GitHub Student Developer Pack</p> <p>GitHub - Ignoring files</p> <p>Microsoft - Introduction to Git</p> <p>Microsoft - Getting started with Visual Studio Code</p> <p>Microsoft - Python in Visual Studio Code</p> <p>Microsoft - Using Git source control in VS Code</p> <p>Microsoft - Working with GitHub in VS Code</p>"},{"location":"resources/references/#setting-up","title":"Setting Up","text":""},{"location":"resources/references/#project-overview","title":"References","text":"<p>Scikit Learn - Documentation - this is seriously the gold standard of machine learning software documentation. It contains not only excellent functional documentation but also a user guide to the methods, techniques, and algorithms used. Highly recommend.</p> <p>Scikit Learn - Wisconsin breast cancer dataset</p> <p>Streamlit - Get started</p> <p>Typer - User guide introduction</p> <p>argparse - Parser for CL options, arguments and sub-commands</p>"},{"location":"resources/references/#overview","title":"Project overview","text":""},{"location":"resources/references/#poetry","title":"References","text":"<p>Poetry - Introduction</p> <p>Poetry - Basic usage</p> <p>Poetry - The <code>pyproject.toml</code> file</p> <p>Pip - <code>pyproject.toml</code></p> <p>Python Packaging - Writing you <code>pyproject.toml</code></p> <p>GitHub - Choose an open source license</p>"},{"location":"resources/references/#poetry","title":"Poetry","text":""},{"location":"resources/references/#testing","title":"References","text":"<p>Python - <code>unittest</code> - Unit testing framework</p> <p>Pytest - Get started</p> <p>Microsoft - Python testing in Visual Studio Code</p>"},{"location":"resources/references/#testing","title":"Testing","text":""},{"location":"resources/references/#publishing","title":"References","text":"<p>PyPI</p> <p>Test PyPI</p> <p>Python - Python packing user guide</p> <p>Python - Packaging Python projects</p> <p>Poetry - <code>build</code></p> <p>Poetry - <code>publish</code></p>"},{"location":"resources/references/#publishing","title":"Publishing","text":""},{"location":"resources/references/#documentation","title":"References","text":"<p>Python - PEP 8 - Style guide for Python code</p> <p>Python - PEP 20 - The Zen of Python</p> <p>Python - PEP 257 - Docstring conventions</p> <p>Python - PEP 484 - Type hints</p> <p>MkDocs - Getting started with MkDocs</p> <p>Material for MkDocs - Getting started</p> <p>Read the Docs - Read the Docs tutorial</p>"},{"location":"resources/references/#documentation","title":"Documentation","text":""},{"location":"resources/references/#cicd-pre-commit","title":"References","text":"<p>GitHub - GitHub Actions documentation</p> <p>Black - Getting started</p> <p>Flake8 - Quickstart</p> <p>Mypy - Getting started</p> <p>Isort - Installing and using <code>isort</code></p> <p>Atlassian - Git hooks</p>"},{"location":"resources/references/#pre-commit","title":"CI/CD - Pre-commit","text":""},{"location":"resources/references/#cicd-testing","title":"References","text":"<p>GitHub - Using workflows</p>"},{"location":"resources/references/#cicd-testing","title":"CI/CD - Testing","text":""},{"location":"resources/references/#cicd-publishing","title":"References","text":"<p>GitHub - Collaborating with pull requests</p> <p>GitHub - About pull requests</p> <p>Atlassian - Trunk-based development</p> <p>Developers - Trunk-based development vs Git Flow</p>"},{"location":"resources/references/#cicd-publishing","title":"CI/CD - Publishing","text":""},{"location":"resources/slides/","title":"Slides","text":"<p>Link to slides here.</p> <ul> <li> <p> 1 Introduction</p> </li> <li> <p> 2 Version Control</p> </li> <li> <p> 3 Poetry</p> </li> <li> <p> 4 Publishing</p> </li> </ul>"}]}